{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAqC8xXmZ1Av"
   },
   "source": [
    "## Convolutional Neural Network \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z8CfGD5Z1Ay"
   },
   "source": [
    "In this notebook you will learn to distinguish dogs from cats!\n",
    "\n",
    "Data:\n",
    "https://drive.google.com/drive/folders/1nzVk4GOvKR6P87uPszUkKMPtaXV_wrZf?usp=sharing\n",
    "\n",
    "Fill all the necessary gaps in cells below and fit neural networks for solving the binary classification task.\n",
    "\n",
    "## Task 1:\n",
    "\n",
    "1. Build and fit CNN with 3 convolutional layers for binary classification\n",
    "2. Evaluate accuracy on test data\n",
    "3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n",
    "\n",
    "First, let's load all the necessary functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "HyzNnZpdZ1A4",
    "outputId": "d588b0a5-de6a-426b-dd7e-f01f7ec78992"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['/device:GPU:0']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K._get_available_gpus()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.config.get_visible_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS-6t0_XZ1BL"
   },
   "source": [
    "The images collected for training and testing the deep learning model must be prepared: split the entire set into a training, validation and test sample, observing the balancing of classes (with binary classification they should be approximately equal in all three samples).\n",
    "\n",
    "This has _already_ been done: in the Cats_and_Dogs directory there are three subdirectories: train, test and val - training, test and validation samples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ejt0NSnVZ1BP"
   },
   "outputs": [],
   "source": [
    "# Initialize the folders with train, test and validation datasets (in \"/My Drive/...\" or from your local repository where you have downloaded data):\n",
    "\n",
    "train = './Cats_and_Dogs/train'\n",
    "val =   './Cats_and_Dogs/val'\n",
    "test =  './Cats_and_Dogs/test'\n",
    "\n",
    "# The shape of the RGB image\n",
    "img_width, img_height, channels = 150, 150, 3 # you can try different sizes\n",
    "\n",
    "# input shape\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# position matters!\n",
    "# Number_of_channels can be at the first or the last position\n",
    "# in our case - \"channels last\"\n",
    "\n",
    "# minibatch size\n",
    "batch_size = 128\n",
    "# train set size\n",
    "nb_train_samples = 20000\n",
    "# validation set size \n",
    "nb_validation_samples = 2490\n",
    "# test set size\n",
    "nb_test_samples = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYe-jLGbZ1Bh"
   },
   "source": [
    "## Prepare the data.\n",
    "\n",
    "You don’t have to manually change the shapes of 25000 images and convert them into the necessary format for keras (img_width, img_height, 3).\n",
    "\n",
    "We will use the built-in image preprocessing function _ImageGenerator()_.\n",
    "\n",
    "It performs scaling, resizes selected images and prepares batches (mini-samples) to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "Ncx9lh6LZ1Bk",
    "outputId": "74fe1156-17d2-4f45-f589-520a5fc2d0b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 2490 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GthRQyZHZ1CI"
   },
   "source": [
    "Set the network architecture by sequentially adding layers to it:\n",
    "1. A convolutional layer with 16 neurons, filter size 3x3. Activation function - 'relu'\n",
    "2. MaxPooling layer with filter size 2x2.\n",
    "3. A convolutional layer with 32 neurons, filter size 3x3. Activation function - 'relu'\n",
    "4. MaxPooling layer with filter size 2x2.\n",
    "5. A convolutional layer with 64 neurons, filter size 3x3. Activation function - 'relu'\n",
    "6. MaxPooling layer with filter size 2x2.\n",
    "7. Operation model.add (Flatten ()), which makes a one-dimensional vector of the resulting feature maps.\n",
    "8. A fully connected layer with 64 neurons. Activation function - 'relu'\n",
    "9. Use model.add (Dropout (0.5)) which excludes the edge from the current layer in the computational graph with a 50% probability to avoid overfitting.\n",
    "10. A fully connected layer with 1 neuron. Activation function - 'sigmoid', because binary classification model.\n",
    "\n",
    "Add to the model all the missing layers, by analogy with the already specified.\n",
    "Keras documentation: https://keras.io/layers/about-keras-layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yNik7qzRZ1CU"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1: +Convolutional\n",
    "# For example:\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "# 2: +Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 3:\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "#     +Relu\n",
    "model.add(Activation('relu'))\n",
    "# 4:  +Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 5:  +Convolutional\n",
    "#     +Relu\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "# 6:  +Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 7:  +Flattening\n",
    "model.add(Flatten())\n",
    "# 8:  +Dense\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "#     +ReLu\n",
    "# 9:  +Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# 10: +Dense\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#     +Sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0nNS5cLjZ1Cg"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BzqPxMJdZ1Cu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\AppData\\Local\\Temp/ipykernel_17904/135310917.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 99s 631ms/step - loss: 0.6632 - accuracy: 0.5931 - val_loss: 0.5934 - val_accuracy: 0.6645\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 96s 612ms/step - loss: 0.5632 - accuracy: 0.7059 - val_loss: 0.5231 - val_accuracy: 0.7356\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 97s 619ms/step - loss: 0.5159 - accuracy: 0.7529 - val_loss: 0.5346 - val_accuracy: 0.7311\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 97s 623ms/step - loss: 0.4802 - accuracy: 0.7808 - val_loss: 0.4659 - val_accuracy: 0.7817\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 98s 630ms/step - loss: 0.4379 - accuracy: 0.8051 - val_loss: 0.4366 - val_accuracy: 0.7985\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 99s 637ms/step - loss: 0.4147 - accuracy: 0.8212 - val_loss: 0.4051 - val_accuracy: 0.8191\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 99s 631ms/step - loss: 0.3874 - accuracy: 0.8344 - val_loss: 0.4410 - val_accuracy: 0.7948\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 100s 639ms/step - loss: 0.3535 - accuracy: 0.8480 - val_loss: 0.3964 - val_accuracy: 0.8215\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 100s 639ms/step - loss: 0.3381 - accuracy: 0.8583 - val_loss: 0.4114 - val_accuracy: 0.8150\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 99s 635ms/step - loss: 0.3078 - accuracy: 0.8683 - val_loss: 0.3905 - val_accuracy: 0.8314\n"
     ]
    }
   ],
   "source": [
    "# use the generator to train the model (analogue of the fit method)\n",
    "# 1 epoch of training on a CPU will take 4-6 minutes. The GPU is an ~order of magnitude faster.\n",
    "# THE FIRST EPOCH USUALLY TAKES MUCH LARGER TIME AS KERAS SHOULD BUILD THE COMPUTATIONAL GRAPH\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=10, # try different number of epochs: 10, 15, 20; check the loss and accuracy;\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBMrJqBHZ1DT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\AppData\\Local\\Temp/ipykernel_17904/1141562015.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: if the accuracy on test data after 15 epochs is less than 80% smth goes wrong\n",
    "\n",
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch = np.linspace(1, 10, 10)\n",
    "loss = [0.5934, 0.5231, 0.5346, 0.4659, 0.4386, 0.4051, 0.4410, 0.3964, 0.4114, 0.3905]\n",
    "accuracy = [0.6645, 0.7356, 0.7833, 0.7817, 0.8191, 0.8183, 0.7948, 0.8215, 0.8150, 0.8314]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epoch, loss, label=\"Loss\")\n",
    "plt.plot(epoch, accuracy, label=\"Accuracy\")\n",
    "plt.title('Metrics on training', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mle_LO6XMJ62"
   },
   "source": [
    "Plot the graphs: \n",
    "\n",
    "- Loss(Number of epochs)\n",
    "\n",
    "- Accuracy(Number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "icBG1BT0WVSE",
    "outputId": "a7d30910-38da-43ee-8d74-040f7bd6d922",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "img = mpimg.imread('./Deeper.jpeg')\n",
    "plt.figure(figsize = (10,20))\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QESIOnCPZ1Dz"
   },
   "source": [
    "Let's try to improve the quality of recognition, using the method of transfer lerning. \n",
    "\n",
    "We will use weights of deep neural networks already trained on large dataset such as  ImageNet, and provide fine tuning of several additional dense layers on new data relevant to the current classification task. The more new images will differ from those on which the network has been trained, the more layers will need to be “retrained” in order to get good classification accuracy. The intuition here is that the model has already learned how to highlight the necessary features on the images in the large dataset, it only needs to be “tweaked” for a specific task.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "1. Build and fit Transfer Learning model using pre-trained VGG16-model weights from keras application.\n",
    "2. Do the same with **another avaliable pre-trained deep learning model** from keras application https://keras.io/api/applications/.\n",
    "2. Evaluate accuracy on test data for p.1 and p.2\n",
    "3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n",
    "4. Check the performance of your model with the custom image of cat or dog (so the model will tell which class this image belongs to). Develop the function for the inference of the best algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md_9fT-nZ1D2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# First, download the weights of the VGG16 network trained on the ImageNet dataset:\n",
    "\n",
    "vgg16_net = vgg16.VGG16(weights='imagenet',\n",
    "                        include_top=False,      # we take only the \"convolution\" part, the last layers we add ourselves\n",
    "                        input_shape=(150, 150, 3))\n",
    "vgg16_net.trainable = False               # clearly prescribe that we do NOT overload the network.\n",
    "                                          # Weights VGG16 in the process of learning will remain unchanged!\n",
    "\n",
    "vgg16_net.summary()                       # pay attention to the number of trained and untrained parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_DTDXqWZ1EG"
   },
   "source": [
    "We construct our model of \"transfer learning\" by adding two fully connected layers to VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKYlhGqTZ1EJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# add layers to VGG16:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vgg16_net)\n",
    "\n",
    "# + flattening\n",
    "model.add(Flatten())\n",
    "# + Dense fully connected layer with 256 neurons\n",
    "model.add(Dense(256))\n",
    "# + ReLu\n",
    "model.add(Activation('relu'))\n",
    "# + Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# + Dense layer with 1 neuron\n",
    "model.add(Dense(1))\n",
    "# + sigmoid\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKU1pQEeZ1Ea",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(lr=1e-5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxBZMbzAZ1Ex"
   },
   "source": [
    "E.g., it was like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "MKMm7XjBXWJi",
    "outputId": "f8cd5a19-18dd-4bdf-c16b-c8cb865ee3ae",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./VGG16.png')\n",
    "plt.figure(figsize = (10,20))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAPd3c7SZ1FP"
   },
   "source": [
    "and it becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "P8Llp_iqXSu5",
    "outputId": "bd3269a5-3822-4b40-8621-6dd6b505501e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./VGG162.png')\n",
    "plt.figure(figsize = (10,20))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNX7L-MIZ1FX",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# We also use the generator to train the model (similar to the fit method)\n",
    "# Without using a GPU, learning 1 epoch of such a network will take about an hour. Plan your time =)\n",
    "# If you have access to a GPU, you can try 10-12 epochs - the quality should increase even more.\n",
    "with tf.device('/CPU:0'):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMCxq21YZ1Fh",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_and_Transfer_Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}