{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw4 (3).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Soft deadline: `30.03.2022 23:59`"
   ],
   "metadata": {
    "id": "nXpkXz1QJmhJ"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxy7euTpCbGp"
   },
   "source": [
    "In this homework you will understand the fine-tuning procedure and get acquainted with Huggingface Datasets library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_1MXcMymXeCx"
   },
   "source": [
    "# ! pip install datasets\n",
    "# ! pip install transformers"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (4.63.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: dill in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (4.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: requests in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: click in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\gto_n\\anaconda3\\envs\\trainingprograms\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FykUK-TFXf-2"
   },
   "source": [
    "For our goals we will use [Datasets](https://huggingface.co/docs/datasets/) library and take `yahoo_answers_topics` dataset - the task of this dataset is to divide documents on 10 topic categories. More detiled information can be found on the dataset [page](https://huggingface.co/datasets/viewer/).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ebsFAQsgXNB0"
   },
   "source": [
    "from datasets import load_dataset"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UbzxZi42XOUG"
   },
   "source": [
    "dataset = load_dataset('yahoo_answers_topics') # the result is a dataset dictionary of train and test splits in this case"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yahoo_answers_topics (C:\\Users\\gto_n\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f72cf632a77498aba447a980c3d6f21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4U4YUOB5W8uG"
   },
   "source": [
    "# Fine-tuning the model** (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Take the code from here https://huggingface.co/docs/transformers/training#finetune-in-native-pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZDYIq9l7CYBR"
   },
   "source": [
    "from transformers import (ElectraTokenizer, ElectraForSequenceClassification,\n",
    "                          get_scheduler, pipeline, ElectraForMaskedLM, ElectraModel,  TrainingArguments, Trainer)\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_metric"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElZ6k36rb0VG"
   },
   "source": [
    "Fine-tuning procedure on the end task consists of adding additional layers on the top of the pre-trained model. The resulting model can be tuned fully (passing gradients through the all model) or partially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNEmksaPb3Uu"
   },
   "source": [
    "**Task**: \n",
    "- load tokenizer and model\n",
    "- look at the predictions of the model as-is before any fine-tuning\n",
    "\n",
    "\n",
    "```\n",
    "- Why don't you ask [MASK]?\n",
    "- What is [MASK]\n",
    "- Let's talk about [MASK] physics\n",
    "```\n",
    "\n",
    "- convert `best_answer` to the input tokens (supporting function for dataset is provided below) \n",
    "\n",
    "```\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "```\n",
    "\n",
    "- define optimizer, sheduler (optional)\n",
    "- fine-tune the model (write the training loop), plot the loss changes and measure results in terms of weighted F1 score\n",
    "- get the masked word prediction (sample sentences above) on the fine-tuned model, why the results as they are and what should be done in order to change that (write down your answer)\n",
    "- Tune the training hyperparameters (and write down your results).\n",
    "\n",
    "**Tips**:\n",
    "- The easiest way to get predictions is to use transformers `pipeline` function \n",
    "- Do not forget to set `num_labels` parameter, when initializing the model\n",
    "- To convert data to batches use `DataLoader`\n",
    "- Even the `small` version of Electra can be long to train, so you can take data sample (>= 5000 and set seed for reproducibility)\n",
    "- You may want to try freezing (do not update the pretrained model weights) all the layers exept the ones for classification, in that case use:\n",
    "\n",
    "\n",
    "```\n",
    "for param in model.electra.parameters():\n",
    "      param.requires_grad = False\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8yqAAFqZcwbu"
   },
   "source": [
    "MODEL_NAME = \"google/electra-small-generator\"\n",
    "TOKENIZER_NAME = \"google/electra-small-generator\""
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(TOKENIZER_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.bias', 'generator_lm_head.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_topics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model = MODEL_NAME,\n",
    "    tokenizer = TOKENIZER_NAME\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.5343012809753418, 'token': 2033, 'token_str': 'me', 'sequence': \"why don't you ask me?\"}, {'score': 0.081960029900074, 'token': 3980, 'token_str': 'questions', 'sequence': \"why don't you ask questions?\"}, {'score': 0.043953459709882736, 'token': 2068, 'token_str': 'them', 'sequence': \"why don't you ask them?\"}, {'score': 0.040172502398490906, 'token': 2339, 'token_str': 'why', 'sequence': \"why don't you ask why?\"}, {'score': 0.030024180188775063, 'token': 4426, 'token_str': 'yourself', 'sequence': \"why don't you ask yourself?\"}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"Why don't you ask [MASK]?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9262325167655945, 'token': 1029, 'token_str': '?', 'sequence': 'what is?'}, {'score': 0.051567427814006805, 'token': 1012, 'token_str': '.', 'sequence': 'what is.'}, {'score': 0.021510528400540352, 'token': 999, 'token_str': '!', 'sequence': 'what is!'}, {'score': 0.00011964981240453199, 'token': 1011, 'token_str': '-', 'sequence': 'what is -'}, {'score': 0.00010928453411906958, 'token': 1000, 'token_str': '\"', 'sequence': 'what is \"'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"What is [MASK]\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.2402748167514801, 'token': 8559, 'token_str': 'quantum', 'sequence': \"let's talk about quantum physics\"}, {'score': 0.21258684992790222, 'token': 9373, 'token_str': 'theoretical', 'sequence': \"let's talk about theoretical physics\"}, {'score': 0.05639376491308212, 'token': 10811, 'token_str': 'particle', 'sequence': \"let's talk about particle physics\"}, {'score': 0.03320787847042084, 'token': 2613, 'token_str': 'real', 'sequence': \"let's talk about real physics\"}, {'score': 0.022627927362918854, 'token': 8045, 'token_str': 'mathematical', 'sequence': \"let's talk about mathematical physics\"}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"Let's talk about [MASK] physics\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\gto_n\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902\\cache-e499894db125bdb8.arrow\n",
      "Loading cached processed dataset at C:\\Users\\gto_n\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902\\cache-350eb3ac1b93492c.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 0,\n 'topic': 4,\n 'question_title': \"why doesn't an optical mouse work on a glass table?\",\n 'question_content': 'or even on some surfaces?',\n 'best_answer': 'Optical mice use an LED and a camera to rapidly capture images of the surface beneath the mouse.  The infomation from the camera is analyzed by a DSP (Digital Signal Processor) and used to detect imperfections in the underlying surface and determine motion. Some materials, such as glass, mirrors or other very shiny, uniform surfaces interfere with the ability of the DSP to accurately analyze the surface beneath the mouse.  \\\\nSince glass is transparent and very uniform, the mouse is unable to pick up enough imperfections in the underlying surface to determine motion.  Mirrored surfaces are also a problem, since they constantly reflect back the same image, causing the DSP not to recognize motion properly. When the system is unable to see surface changes associated with movement, the mouse will not work properly.',\n 'input_ids': [101,\n  9380,\n  12328,\n  2224,\n  2019,\n  2419,\n  1998,\n  1037,\n  4950,\n  2000,\n  5901,\n  5425,\n  4871,\n  1997,\n  1996,\n  3302,\n  4218,\n  1996,\n  8000,\n  1012,\n  1996,\n  18558,\n  28649,\n  2013,\n  1996,\n  4950,\n  2003,\n  16578,\n  2011,\n  1037,\n  16233,\n  2361,\n  1006,\n  3617,\n  4742,\n  13151,\n  1007,\n  1998,\n  2109,\n  2000,\n  11487,\n  29238,\n  8496,\n  1999,\n  1996,\n  10318,\n  3302,\n  1998,\n  5646,\n  4367,\n  1012,\n  2070,\n  4475,\n  1010,\n  2107,\n  2004,\n  3221,\n  1010,\n  13536,\n  2030,\n  2060,\n  2200,\n  12538,\n  1010,\n  6375,\n  9972,\n  15115,\n  2007,\n  1996,\n  3754,\n  1997,\n  1996,\n  16233,\n  2361,\n  2000,\n  14125,\n  17908,\n  1996,\n  3302,\n  4218,\n  1996,\n  8000,\n  1012,\n  1032,\n  24978,\n  2378,\n  3401,\n  3221,\n  2003,\n  13338,\n  1998,\n  2200,\n  6375,\n  1010,\n  1996,\n  8000,\n  2003,\n  4039,\n  2000,\n  4060,\n  2039,\n  2438,\n  29238,\n  8496,\n  1999,\n  1996,\n  10318,\n  3302,\n  2000,\n  5646,\n  4367,\n  1012,\n  22243,\n  9972,\n  2024,\n  2036,\n  1037,\n  3291,\n  1010,\n  2144,\n  2027,\n  7887,\n  8339,\n  2067,\n  1996,\n  2168,\n  3746,\n  1010,\n  4786,\n  1996,\n  16233,\n  2361,\n  2025,\n  2000,\n  6807,\n  4367,\n  7919,\n  1012,\n  2043,\n  1996,\n  2291,\n  2003,\n  4039,\n  2000,\n  2156,\n  3302,\n  3431,\n  3378,\n  2007,\n  2929,\n  1010,\n  1996,\n  8000,\n  2097,\n  2025,\n  2147,\n  7919,\n  1012,\n  102,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2070 Super\n"
     ]
    },
    {
     "data": {
      "text/plain": "ElectraForSequenceClassification(\n  (electra): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n      (position_embeddings): Embedding(512, 128)\n      (token_type_embeddings): Embedding(2, 128)\n      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=256, out_features=1024, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=1024, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): ElectraClassificationHead(\n    (dense): Linear(in_features=256, out_features=256, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=256, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['topic', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['topic', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tokenized_datasets.remove_columns(['id', 'best_answer', 'question_title', 'question_content'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename_column(\"topic\", \"labels\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'labels': 4,\n 'input_ids': [101,\n  9380,\n  12328,\n  2224,\n  2019,\n  2419,\n  1998,\n  1037,\n  4950,\n  2000,\n  5901,\n  5425,\n  4871,\n  1997,\n  1996,\n  3302,\n  4218,\n  1996,\n  8000,\n  1012,\n  1996,\n  18558,\n  28649,\n  2013,\n  1996,\n  4950,\n  2003,\n  16578,\n  2011,\n  1037,\n  16233,\n  2361,\n  1006,\n  3617,\n  4742,\n  13151,\n  1007,\n  1998,\n  2109,\n  2000,\n  11487,\n  29238,\n  8496,\n  1999,\n  1996,\n  10318,\n  3302,\n  1998,\n  5646,\n  4367,\n  1012,\n  2070,\n  4475,\n  1010,\n  2107,\n  2004,\n  3221,\n  1010,\n  13536,\n  2030,\n  2060,\n  2200,\n  12538,\n  1010,\n  6375,\n  9972,\n  15115,\n  2007,\n  1996,\n  3754,\n  1997,\n  1996,\n  16233,\n  2361,\n  2000,\n  14125,\n  17908,\n  1996,\n  3302,\n  4218,\n  1996,\n  8000,\n  1012,\n  1032,\n  24978,\n  2378,\n  3401,\n  3221,\n  2003,\n  13338,\n  1998,\n  2200,\n  6375,\n  1010,\n  1996,\n  8000,\n  2003,\n  4039,\n  2000,\n  4060,\n  2039,\n  2438,\n  29238,\n  8496,\n  1999,\n  1996,\n  10318,\n  3302,\n  2000,\n  5646,\n  4367,\n  1012,\n  22243,\n  9972,\n  2024,\n  2036,\n  1037,\n  3291,\n  1010,\n  2144,\n  2027,\n  7887,\n  8339,\n  2067,\n  1996,\n  2168,\n  3746,\n  1010,\n  4786,\n  1996,\n  16233,\n  2361,\n  2025,\n  2000,\n  6807,\n  4367,\n  7919,\n  1012,\n  2043,\n  1996,\n  2291,\n  2003,\n  4039,\n  2000,\n  2156,\n  3302,\n  3431,\n  3378,\n  2007,\n  2929,\n  1010,\n  1996,\n  8000,\n  2097,\n  2025,\n  2147,\n  7919,\n  1012,\n  102,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\gto_n\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902\\cache-9b5bf21789580198.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\gto_n\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902\\cache-7df4c0de2ea69116.arrow\n"
     ]
    }
   ],
   "source": [
    "df.set_format(\"torch\")\n",
    "train_df = df['train'].shuffle(seed=42).select(range(50_000))\n",
    "test_df = df['test'].shuffle(seed=42).select(range(10_000))\n",
    "train_dl = DataLoader(train_df, shuffle=True, batch_size=16)\n",
    "test_dl = DataLoader(test_df, batch_size=16)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "metric = load_metric(\"f1\")\n",
    "num_epochs = 20\n",
    "num_training_steps = num_epochs * len(train_dl)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/62500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d618dd5fb9a45d1b1c8c4b7caeec79b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "f1 = []\n",
    "losses = []\n",
    "f1s = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dl:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    model.eval()\n",
    "    for batch in test_dl:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    losses.append((torch.mean(loss).cpu().detach().numpy()))\n",
    "    f1s.append(metric.compute(average='weighted')['f1'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.5751074275464533,\n 0.5859619069222264,\n 0.5863147956679378,\n 0.5841396094630567,\n 0.5827219703590326,\n 0.5720338302954533,\n 0.5772590816055251,\n 0.5735825910002859,\n 0.5757435266655629]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[array(1.5970341, dtype=float32),\n array(1.6109067, dtype=float32),\n array(1.3168491, dtype=float32),\n array(0.8061613, dtype=float32),\n array(0.7696772, dtype=float32),\n array(1.4578874, dtype=float32),\n array(0.57082564, dtype=float32),\n array(0.85723084, dtype=float32),\n array(0.4513181, dtype=float32)]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(f1s)\n",
    "plt.title('F1-score metric dynamic')\n",
    "plt.xlabel('Number of epoch')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(losses)\n",
    "plt.title('AdamW metric dynamic')\n",
    "plt.xlabel('Number of epoch')\n",
    "plt.ylabel('AdamW')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# ! pip install optuna\n",
    "# ! pip install ray[tune]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def model_init():\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_df,\n",
    "    eval_dataset=test_df,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-03-30 06:00:14,455]\u001B[0m A new study created in memory with name: no-name-17cef9e5-b9b3-430f-850a-483e5e04523c\u001B[0m\n",
      "Trial:\n",
      "C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6250\n",
      "\u001B[33m[W 2022-03-30 06:00:15,077]\u001B[0m Trial 0 failed because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 6.57 GiB already allocated; 0 bytes free; 6.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\integrations.py\", line 154, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py\", line 1400, in train\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py\", line 1984, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py\", line 2016, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py\", line 1000, in forward\n",
      "    discriminator_hidden_states = self.electra(\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py\", line 916, in forward\n",
      "    hidden_states = self.encoder(\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py\", line 584, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py\", line 470, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py\", line 397, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py\", line 317, in forward\n",
      "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 6.57 GiB already allocated; 0 bytes free; 6.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 6.57 GiB already allocated; 0 bytes free; 6.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [40]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m best_run \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhyperparameter_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py:1891\u001B[0m, in \u001B[0;36mTrainer.hyperparameter_search\u001B[1;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001B[0m\n\u001B[0;32m   1883\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_objective \u001B[38;5;241m=\u001B[39m default_compute_objective \u001B[38;5;28;01mif\u001B[39;00m compute_objective \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m compute_objective\n\u001B[0;32m   1885\u001B[0m backend_dict \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1886\u001B[0m     HPSearchBackend\u001B[38;5;241m.\u001B[39mOPTUNA: run_hp_search_optuna,\n\u001B[0;32m   1887\u001B[0m     HPSearchBackend\u001B[38;5;241m.\u001B[39mRAY: run_hp_search_ray,\n\u001B[0;32m   1888\u001B[0m     HPSearchBackend\u001B[38;5;241m.\u001B[39mSIGOPT: run_hp_search_sigopt,\n\u001B[0;32m   1889\u001B[0m     HPSearchBackend\u001B[38;5;241m.\u001B[39mWANDB: run_hp_search_wandb,\n\u001B[0;32m   1890\u001B[0m }\n\u001B[1;32m-> 1891\u001B[0m best_run \u001B[38;5;241m=\u001B[39m backend_dict[backend](\u001B[38;5;28mself\u001B[39m, n_trials, direction, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1893\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhp_search_backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1894\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m best_run\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\integrations.py:164\u001B[0m, in \u001B[0;36mrun_hp_search_optuna\u001B[1;34m(trainer, n_trials, direction, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m n_jobs \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_jobs\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    163\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39mdirection, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 164\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_objective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    165\u001B[0m best_trial \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m BestRun(\u001B[38;5;28mstr\u001B[39m(best_trial\u001B[38;5;241m.\u001B[39mnumber), best_trial\u001B[38;5;241m.\u001B[39mvalue, best_trial\u001B[38;5;241m.\u001B[39mparams)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\optuna\\study\\study.py:400\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    393\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    394\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    395\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis feature will be removed in v4.0.0. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    396\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    397\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    398\u001B[0m     )\n\u001B[1;32m--> 400\u001B[0m \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m show_progress_bar:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\optuna\\study\\_optimize.py:264\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch):\n\u001B[1;32m--> 264\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m trial\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    210\u001B[0m     thread\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 213\u001B[0m     value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\integrations.py:154\u001B[0m, in \u001B[0;36mrun_hp_search_optuna.<locals>._objective\u001B[1;34m(trial, checkpoint_dir)\u001B[0m\n\u001B[0;32m    152\u001B[0m             checkpoint \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(checkpoint_dir, subdir)\n\u001B[0;32m    153\u001B[0m trainer\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 154\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py:1400\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1398\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[0;32m   1399\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1400\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1403\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[0;32m   1405\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   1406\u001B[0m ):\n\u001B[0;32m   1407\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   1408\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py:1984\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   1981\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   1983\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocast_smart_context_manager():\n\u001B[1;32m-> 1984\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1986\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1987\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\trainer.py:2016\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m   2014\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2015\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2016\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m   2017\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[0;32m   2018\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[0;32m   2019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:1000\u001B[0m, in \u001B[0;36mElectraForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    992\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    993\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m    995\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m    996\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m    997\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    998\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1000\u001B[0m discriminator_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43melectra\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1004\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1005\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1007\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1008\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1009\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1010\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1012\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m discriminator_hidden_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1013\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(sequence_output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:916\u001B[0m, in \u001B[0;36mElectraModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membeddings_project\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    914\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings_project(hidden_states)\n\u001B[1;32m--> 916\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:584\u001B[0m, in \u001B[0;36mElectraEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    575\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    576\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    577\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    581\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    582\u001B[0m     )\n\u001B[0;32m    583\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 584\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    594\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:470\u001B[0m, in \u001B[0;36mElectraLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    459\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    460\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    467\u001B[0m ):\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    469\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 470\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    473\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    475\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    477\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:397\u001B[0m, in \u001B[0;36mElectraAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    389\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    395\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    396\u001B[0m ):\n\u001B[1;32m--> 397\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    406\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    407\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:317\u001B[0m, in \u001B[0;36mElectraSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    314\u001B[0m         relative_position_scores_key \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39meinsum(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbhrd,lrd->bhlr\u001B[39m\u001B[38;5;124m\"\u001B[39m, key_layer, positional_embedding)\n\u001B[0;32m    315\u001B[0m         attention_scores \u001B[38;5;241m=\u001B[39m attention_scores \u001B[38;5;241m+\u001B[39m relative_position_scores_query \u001B[38;5;241m+\u001B[39m relative_position_scores_key\n\u001B[1;32m--> 317\u001B[0m attention_scores \u001B[38;5;241m=\u001B[39m \u001B[43mattention_scores\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention_head_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;66;03m# Apply the attention mask is (precomputed for all layers in ElectraModel forward() function)\u001B[39;00m\n\u001B[0;32m    320\u001B[0m     attention_scores \u001B[38;5;241m=\u001B[39m attention_scores \u001B[38;5;241m+\u001B[39m attention_mask\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 6.57 GiB already allocated; 0 bytes free; 6.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The second approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['topic', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['topic', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tokenized_datasets.remove_columns(['id', 'question_title', 'question_content', 'best_answer'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 60000\n    })\n})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename_column(\"topic\", \"labels\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'num_examples'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m training_args \u001B[38;5;241m=\u001B[39m \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./results\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2e-5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_eval_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: TrainingArguments.__init__() got an unexpected keyword argument 'num_examples'"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=df[\"train\"].shuffle(seed=42).select(range(5_000)),\n",
    "    eval_dataset=df[\"test\"].shuffle(seed=42).select(range(1_000)),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gto_n\\anaconda3\\envs\\TrainingPrograms\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1565\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1565 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./results\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./results\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to ./results\\checkpoint-1000\n",
      "Configuration saved in ./results\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./results\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ./results\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to ./results\\checkpoint-1500\n",
      "Configuration saved in ./results\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./results\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in ./results\\checkpoint-1500\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=1565, training_loss=1.220321874648999, metrics={'train_runtime': 349.9397, 'train_samples_per_second': 71.441, 'train_steps_per_second': 4.472, 'total_flos': 735648921600000.0, 'train_loss': 1.220321874648999, 'epoch': 5.0})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 1.293127417564392,\n 'eval_f1': 0.5815221413033447,\n 'eval_runtime': 5.0482,\n 'eval_samples_per_second': 198.091,\n 'eval_steps_per_second': 12.48,\n 'epoch': 5.0}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}